{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f3551217",
      "metadata": {
        "id": "f3551217"
      },
      "source": [
        "# Web Server Log Analysis - Python Take-Home Assessment"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98eb0efa",
      "metadata": {
        "id": "98eb0efa"
      },
      "source": [
        "## Overview\n",
        "This assessment involves analyzing the Calgary HTTP dataset, which contains approximately one year's worth of HTTP requests to the University of Calgary's Computer Science web server. You'll work with real-world web server log data to extract meaningful insights and demonstrate your Python data analysis skills."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81debeba",
      "metadata": {
        "id": "81debeba"
      },
      "source": [
        "## Part 1: Data Loading and Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e728b83",
      "metadata": {
        "id": "9e728b83"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* Work in the cells below - You can add as many cells as needed for data loading, cleaning, and exploration\n",
        "* Import required libraries\n",
        "* Implement data loading and cleaning - Create functions to download, parse, and clean the log data\n",
        "* Explore the data - Understand the structure and identify any data quality issues"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "b2c05313",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2c05313",
        "outputId": "adf7aee5-c1a7-4764-fb50-fb26bed52e13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded: calgary_access_log.gz\n",
            "\n",
            "✅ Loaded 724836 valid log entries.\n",
            "\n",
            "  remotehost                   timestamp                  request  status  \\\n",
            "0      local  24/Oct/1994:13:41:41 -0600  GET index.html HTTP/1.0     200   \n",
            "1      local  24/Oct/1994:13:41:41 -0600       GET 1.gif HTTP/1.0     200   \n",
            "2      local  24/Oct/1994:13:43:13 -0600  GET index.html HTTP/1.0     200   \n",
            "3      local  24/Oct/1994:13:43:14 -0600       GET 2.gif HTTP/1.0     200   \n",
            "4      local  24/Oct/1994:13:43:15 -0600       GET 3.gif HTTP/1.0     200   \n",
            "\n",
            "   bytes                   datetime method        file  protocol extension  \n",
            "0    150  1994-10-24 13:41:41-06:00    GET  index.html  HTTP/1.0      html  \n",
            "1   1210  1994-10-24 13:41:41-06:00    GET       1.gif  HTTP/1.0       gif  \n",
            "2   3185  1994-10-24 13:43:13-06:00    GET  index.html  HTTP/1.0      html  \n",
            "3   2555  1994-10-24 13:43:14-06:00    GET       2.gif  HTTP/1.0       gif  \n",
            "4  36403  1994-10-24 13:43:15-06:00    GET       3.gif  HTTP/1.0       gif  \n"
          ]
        }
      ],
      "source": [
        "import gzip\n",
        "import urllib.request\n",
        "import re\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Download the file\n",
        "url = 'ftp://ita.ee.lbl.gov/traces/calgary_access_log.gz'\n",
        "filename = 'calgary_access_log.gz'\n",
        "urllib.request.urlretrieve(url, filename)\n",
        "print(\"Downloaded:\", filename)\n",
        "\n",
        "# Step 2: Regex pattern for Apache Common Log Format\n",
        "log_pattern = re.compile(\n",
        "    r'(?P<remotehost>\\S+) \\S+ \\S+ \\[(?P<timestamp>[^\\]]+)\\] '\n",
        "    r'\"(?P<request>[^\"]+)\" (?P<status>\\d{3}) (?P<bytes>\\S+)'\n",
        ")\n",
        "\n",
        "# Step 3: Read and parse log lines\n",
        "log_entries = []\n",
        "with gzip.open(filename, 'rt', encoding='utf-8', errors='ignore') as f:\n",
        "    for line in f:\n",
        "        match = log_pattern.match(line)\n",
        "        if match:\n",
        "            data = match.groupdict()\n",
        "\n",
        "            # Parse timestamp\n",
        "            try:\n",
        "                dt = datetime.strptime(data['timestamp'], '%d/%b/%Y:%H:%M:%S %z')\n",
        "            except Exception:\n",
        "                continue\n",
        "\n",
        "            data['datetime'] = dt\n",
        "\n",
        "            # Split the request line into method, file, and protocol\n",
        "            request_parts = data['request'].split()\n",
        "            if len(request_parts) == 3:\n",
        "                data['method'], data['file'], data['protocol'] = request_parts\n",
        "            else:\n",
        "                data['method'], data['file'], data['protocol'] = '', '', ''\n",
        "\n",
        "            # Convert status to int\n",
        "            try:\n",
        "                data['status'] = int(data['status'])\n",
        "            except:\n",
        "                data['status'] = None\n",
        "\n",
        "            # Convert bytes to int, treat '-' as 0\n",
        "            data['bytes'] = int(data['bytes']) if data['bytes'].isdigit() else 0\n",
        "\n",
        "            # Extract file extension if any\n",
        "            if '.' in data['file']:\n",
        "                data['extension'] = data['file'].rsplit('.', 1)[-1].lower()\n",
        "            else:\n",
        "                data['extension'] = ''\n",
        "\n",
        "            log_entries.append(data)\n",
        "\n",
        "# Step 4: Load into pandas DataFrame\n",
        "df = pd.DataFrame(log_entries)\n",
        "\n",
        "# Step 5: Preview the data\n",
        "print(f\"\\n✅ Loaded {len(df)} valid log entries.\\n\")\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e491a4e",
      "metadata": {
        "id": "8e491a4e"
      },
      "source": [
        "## ⚠️ IMPORTANT: Template Questions Section\n",
        "**DO NOT MODIFY THE TEMPLATE BELOW THIS POINT**\n",
        "\n",
        "The following section contains the assessment questions. You may add cells above this section for data loading, cleaning, and exploration, but do not modify the function signatures or structure of the questions below."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80da5c6e",
      "metadata": {
        "id": "80da5c6e"
      },
      "source": [
        "## Part 2: Analysis Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38f1ce65",
      "metadata": {
        "id": "38f1ce65"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* Implement each function according to its docstring specifications\n",
        "* Use the cleaned data you prepared in Part 1\n",
        "* Ensure your functions return the exact data types specified\n",
        "* Test your functions to verify they work correctly\n",
        "* You may add helper functions, but keep the main function signatures unchanged"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afff13fe",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "afff13fe"
      },
      "source": [
        "### Q1: Count of total log records"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "f6264dd7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6264dd7",
        "outputId": "88f26478-d561-457a-e19d-213d6d115910"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer 1:\n",
            "724836\n"
          ]
        }
      ],
      "source": [
        "def total_log_records() -> int:\n",
        "    \"\"\"\n",
        "    Q1: Count of total log records.\n",
        "\n",
        "    Objective:\n",
        "        Determine the total number of HTTP log entries in the dataset.\n",
        "        Each line in the log file represents one HTTP request.\n",
        "\n",
        "    Returns:\n",
        "        int: Total number of log entries.\n",
        "    \"\"\"\n",
        "    # TODO: Implement Total number of log entries.\n",
        "\n",
        "    return len(df)  # Placeholder return\n",
        "\n",
        "\n",
        "answer1 = total_log_records()\n",
        "print(\"Answer 1:\")\n",
        "print(answer1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78c5141e",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "78c5141e"
      },
      "source": [
        "### Q2: Count of unique hosts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "fcbccae5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcbccae5",
        "outputId": "e7148334-fc16-40e3-d25e-103a854e8dea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer 2:\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "def unique_host_count() -> int:\n",
        "    \"\"\"\n",
        "    Q2: Count of unique hosts.\n",
        "\n",
        "    Objective:\n",
        "        Determine how many distinct hosts accessed the server.\n",
        "\n",
        "    Returns:\n",
        "        int: Number of unique hosts.\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: Implement logic to count unique hosts\n",
        "\n",
        "    return df['remotehost'].nunique()\n",
        "\n",
        "\n",
        "answer2 = unique_host_count()\n",
        "print(\"Answer 2:\")\n",
        "print(answer2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2c224d5",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "f2c224d5"
      },
      "source": [
        "### Q3: Date-wise unique filename counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "ac11c680",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac11c680",
        "outputId": "71c43510-e523-4662-bc0c-8c0eb4ba2707"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer 3:\n",
            "{'01-Aug-1995': 670, '01-Jul-1995': 388, '01-Jun-1995': 591, '01-May-1995': 467, '01-Oct-1995': 553, '01-Sep-1995': 329, '02-Apr-1995': 439, '02-Aug-1995': 856, '02-Jul-1995': 398, '02-Jun-1995': 514, '02-May-1995': 702, '02-Oct-1995': 872, '02-Sep-1995': 350, '03-Apr-1995': 796, '03-Aug-1995': 583, '03-Jul-1995': 434, '03-Jun-1995': 399, '03-May-1995': 590, '03-Oct-1995': 847, '03-Sep-1995': 213, '04-Apr-1995': 822, '04-Aug-1995': 716, '04-Jul-1995': 611, '04-Jun-1995': 354, '04-May-1995': 685, '04-Oct-1995': 890, '04-Sep-1995': 341, '05-Apr-1995': 891, '05-Aug-1995': 508, '05-Jul-1995': 608, '05-Jun-1995': 495, '05-May-1995': 609, '05-Oct-1995': 847, '05-Sep-1995': 412, '06-Apr-1995': 679, '06-Aug-1995': 449, '06-Jul-1995': 523, '06-Jun-1995': 663, '06-May-1995': 517, '06-Oct-1995': 869, '06-Sep-1995': 550, '07-Apr-1995': 777, '07-Aug-1995': 609, '07-Jul-1995': 428, '07-Jun-1995': 486, '07-May-1995': 726, '07-Oct-1995': 468, '07-Sep-1995': 591, '08-Apr-1995': 543, '08-Aug-1995': 655, '08-Jul-1995': 277, '08-Jun-1995': 643, '08-May-1995': 657, '08-Oct-1995': 515, '08-Sep-1995': 755, '09-Apr-1995': 627, '09-Aug-1995': 699, '09-Jul-1995': 233, '09-Jun-1995': 468, '09-May-1995': 775, '09-Oct-1995': 743, '09-Sep-1995': 409, '10-Apr-1995': 751, '10-Aug-1995': 636, '10-Jul-1995': 503, '10-Jun-1995': 328, '10-May-1995': 795, '10-Oct-1995': 842, '10-Sep-1995': 456, '11-Apr-1995': 817, '11-Aug-1995': 452, '11-Jul-1995': 572, '11-Jun-1995': 298, '11-May-1995': 600, '11-Oct-1995': 718, '11-Sep-1995': 718, '12-Apr-1995': 888, '12-Aug-1995': 341, '12-Jul-1995': 468, '12-Jun-1995': 520, '12-May-1995': 469, '12-Sep-1995': 719, '13-Apr-1995': 614, '13-Aug-1995': 464, '13-Jul-1995': 500, '13-Jun-1995': 466, '13-May-1995': 289, '13-Sep-1995': 774, '14-Apr-1995': 354, '14-Aug-1995': 590, '14-Jul-1995': 552, '14-Jun-1995': 590, '14-May-1995': 326, '14-Sep-1995': 719, '15-Apr-1995': 419, '15-Aug-1995': 482, '15-Jul-1995': 385, '15-Jun-1995': 480, '15-May-1995': 584, '15-Sep-1995': 710, '16-Apr-1995': 435, '16-Aug-1995': 602, '16-Jul-1995': 300, '16-Jun-1995': 530, '16-May-1995': 432, '16-Sep-1995': 565, '17-Apr-1995': 446, '17-Aug-1995': 538, '17-Jul-1995': 568, '17-Jun-1995': 384, '17-May-1995': 509, '17-Sep-1995': 467, '18-Apr-1995': 453, '18-Aug-1995': 493, '18-Jul-1995': 558, '18-Jun-1995': 359, '18-May-1995': 529, '18-Sep-1995': 658, '19-Apr-1995': 701, '19-Aug-1995': 378, '19-Jul-1995': 472, '19-Jun-1995': 613, '19-May-1995': 499, '19-Sep-1995': 736, '20-Apr-1995': 588, '20-Aug-1995': 396, '20-Jul-1995': 570, '20-Jun-1995': 531, '20-May-1995': 254, '20-Sep-1995': 833, '21-Apr-1995': 713, '21-Aug-1995': 632, '21-Jul-1995': 650, '21-Jun-1995': 625, '21-May-1995': 289, '21-Sep-1995': 801, '22-Apr-1995': 435, '22-Aug-1995': 539, '22-Jul-1995': 445, '22-Jun-1995': 631, '22-May-1995': 478, '22-Sep-1995': 616, '23-Apr-1995': 333, '23-Aug-1995': 661, '23-Jul-1995': 499, '23-Jun-1995': 562, '23-May-1995': 566, '23-Sep-1995': 503, '24-Apr-1995': 529, '24-Aug-1995': 579, '24-Jul-1995': 566, '24-Jun-1995': 397, '24-May-1995': 490, '24-Oct-1994': 229, '24-Sep-1995': 594, '25-Apr-1995': 558, '25-Aug-1995': 596, '25-Jul-1995': 589, '25-Jun-1995': 570, '25-May-1995': 488, '25-Oct-1994': 319, '25-Sep-1995': 724, '26-Apr-1995': 648, '26-Aug-1995': 395, '26-Jul-1995': 599, '26-Jun-1995': 638, '26-May-1995': 425, '26-Oct-1994': 377, '26-Sep-1995': 871, '27-Apr-1995': 616, '27-Aug-1995': 437, '27-Jul-1995': 615, '27-Jun-1995': 518, '27-May-1995': 245, '27-Oct-1994': 385, '27-Sep-1995': 827, '28-Apr-1995': 637, '28-Aug-1995': 549, '28-Jul-1995': 565, '28-Jun-1995': 573, '28-May-1995': 205, '28-Oct-1994': 400, '28-Sep-1995': 868, '29-Apr-1995': 449, '29-Aug-1995': 512, '29-Jul-1995': 321, '29-Jun-1995': 470, '29-May-1995': 465, '29-Oct-1994': 255, '29-Sep-1995': 839, '30-Apr-1995': 278, '30-Aug-1995': 594, '30-Jul-1995': 482, '30-Jun-1995': 461, '30-May-1995': 554, '30-Oct-1994': 20, '30-Sep-1995': 651, '31-Aug-1995': 510, '31-Jul-1995': 623, '31-May-1995': 572}\n"
          ]
        }
      ],
      "source": [
        "def datewise_unique_filename_counts() -> dict[str, int]:\n",
        "    \"\"\"\n",
        "    Q3: Date-wise unique filename counts.\n",
        "\n",
        "    Objective:\n",
        "        For each date, count the number of unique filenames that accessed the server.\n",
        "        The date should be in 'dd-MMM-yyyy' format (e.g., '01-Jul-1995').\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary mapping each date to its count of unique filenames.\n",
        "              Example: {'01-Jul-1995': 123, '02-Jul-1995': 150}\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: Implement logic for date-wise unique filename counts\n",
        "    df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')\n",
        "    df['date_str'] = df['datetime'].dt.strftime('%d-%b-%Y')\n",
        "    return df.groupby('date_str')['file'].nunique().to_dict()\n",
        "\n",
        "\n",
        "answer3 = datewise_unique_filename_counts()\n",
        "print(\"Answer 3:\")\n",
        "print(answer3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d2da36a",
      "metadata": {
        "id": "4d2da36a"
      },
      "source": [
        "### Q4: Number of 404 response codes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "d0671865",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0671865",
        "outputId": "7756d68c-8d8e-4f17-9a11-84969ebd2792"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer 4:\n",
            "23517\n"
          ]
        }
      ],
      "source": [
        "def count_404_errors() -> int:\n",
        "    \"\"\"\n",
        "    Q4: Number of 404 response codes.\n",
        "\n",
        "    Objective:\n",
        "        Count how many times the HTTP 404 Not Found status appears in the logs.\n",
        "\n",
        "    Returns:\n",
        "        int: Number of 404 errors.\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: Implement logic to count 404 errors\n",
        "\n",
        "    return df[df['status'] == 404].shape[0]\n",
        "\n",
        "\n",
        "answer4 = count_404_errors()\n",
        "print(\"Answer 4:\")\n",
        "print(answer4)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c73928d2",
      "metadata": {
        "id": "c73928d2"
      },
      "source": [
        "### Q5: Top 15 filenames with 404 responses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "358f0523",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "358f0523",
        "outputId": "c927de58-5556-48fd-bdc0-e579b7647194"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer 5:\n",
            "[('index.html', 4694), ('4115.html', 902), ('1611.html', 649), ('5698.xbm', 585), ('710.txt', 408), ('2002.html', 258), ('2177.gif', 193), ('10695.ps', 161), ('6555.html', 153), ('487.gif', 152), ('151.html', 149), ('488.gif', 148), ('3414.gif', 148), ('40.html', 148), ('9678.gif', 142)]\n"
          ]
        }
      ],
      "source": [
        "def top_15_filenames_with_404() -> list[tuple[str, int]]:\n",
        "    \"\"\"\n",
        "    Q5: Top 15 filenames with 404 responses.\n",
        "\n",
        "    Objective:\n",
        "        Identify which requested URLs most frequently resulted in a 404 error.\n",
        "        Return the top 15 filenames sorted by frequency.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of tuples (filename, count), sorted by count in descending order.\n",
        "              Example: [('index.html', 200), ...]\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: Implement logic to find top 15 filenames with 404\n",
        "\n",
        "    errors_404 = df[df['status'] == 404]\n",
        "    top_files = errors_404['file'].value_counts().head(15)\n",
        "    return list(top_files.items())\n",
        "\n",
        "\n",
        "answer5 = top_15_filenames_with_404()\n",
        "print(\"Answer 5:\")\n",
        "print(answer5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6328c88a",
      "metadata": {
        "id": "6328c88a"
      },
      "source": [
        "### Q6: Top 15 file extension with 404 responses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "d0aca8cc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0aca8cc",
        "outputId": "294019e6-94b3-4b14-8f29-e56e240b8c59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer 6:\n",
            "[('html', 12145), ('gif', 7337), ('xbm', 824), ('ps', 754), ('jpg', 531), ('txt', 508), ('', 163), ('htm', 108), ('cgi', 77), ('com', 45), ('z', 41), ('dvi', 40), ('com/', 37), ('ca', 36), ('hmtl', 30)]\n"
          ]
        }
      ],
      "source": [
        "def top_15_ext_with_404() -> list[tuple[str, int]]:\n",
        "    \"\"\"\n",
        "    Q6: Top 15 file extensions with 404 responses.\n",
        "\n",
        "    Objective:\n",
        "        Find which file extensions generated the most 404 errors.\n",
        "        Return the top 15 sorted by number of 404s.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of tuples (extension, count), sorted by count in descending order.\n",
        "              Example: [('html', 45), ...]\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: Implement logic to find top 15 extensions with 404\n",
        "\n",
        "    errors_404 = df[df['status'] == 404]\n",
        "    top_exts = errors_404['extension'].value_counts().head(15)\n",
        "    return list(top_exts.items())\n",
        "\n",
        "\n",
        "answer6 = top_15_ext_with_404()\n",
        "print(\"Answer 6:\")\n",
        "print(answer6)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff52c8ba",
      "metadata": {
        "id": "ff52c8ba"
      },
      "source": [
        "### Q7: Total bandwidth transferred per day for the month of July 1995"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "45f52d9b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45f52d9b",
        "outputId": "e253f900-a646-49fd-d515-7925e083ffb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer 7:\n",
            "{'01-Jul-1995': 11349799, '02-Jul-1995': 8656918, '03-Jul-1995': 13596612, '04-Jul-1995': 26573988, '05-Jul-1995': 19541225, '06-Jul-1995': 19755015, '07-Jul-1995': 9427822, '08-Jul-1995': 5403491, '09-Jul-1995': 4660556, '10-Jul-1995': 14917754, '11-Jul-1995': 22507207, '12-Jul-1995': 17367065, '13-Jul-1995': 15989234, '14-Jul-1995': 19186430, '15-Jul-1995': 15773233, '16-Jul-1995': 9016378, '17-Jul-1995': 19601338, '18-Jul-1995': 17099761, '19-Jul-1995': 17851725, '20-Jul-1995': 20752623, '21-Jul-1995': 25491617, '22-Jul-1995': 8136259, '23-Jul-1995': 9593870, '24-Jul-1995': 22308265, '25-Jul-1995': 24561635, '26-Jul-1995': 24995540, '27-Jul-1995': 25969995, '28-Jul-1995': 36460693, '29-Jul-1995': 11700624, '30-Jul-1995': 23189598, '31-Jul-1995': 30730715}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-279b1ca0eabd>:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  july_df['date_str'] = july_df['datetime'].dt.strftime('%d-%b-%Y')\n"
          ]
        }
      ],
      "source": [
        "def total_bandwidth_per_day() -> dict[str, int]:\n",
        "    \"\"\"\n",
        "    Q7: Total bandwidth transferred per day for the month of July 1995.\n",
        "\n",
        "    Objective:\n",
        "        Sum the number of bytes transferred per day.\n",
        "        Skip entries where the byte field is missing or '-'.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary mapping each date to total bytes transferred.\n",
        "              Example: {'01-Jul-1995': 123456789, ...}\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: Implement logic to compute total bandwidth per day\n",
        "\n",
        "        # Ensure datetime column is in datetime format\n",
        "    df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')\n",
        "\n",
        "    # Filter for July 1995\n",
        "    july_df = df[(df['datetime'].dt.month == 7) & (df['datetime'].dt.year == 1995)]\n",
        "\n",
        "    # Format date and sum bytes\n",
        "    july_df['date_str'] = july_df['datetime'].dt.strftime('%d-%b-%Y')\n",
        "    result = july_df.groupby('date_str')['bytes'].sum().to_dict()\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "answer7 = total_bandwidth_per_day()\n",
        "print(\"Answer 7:\")\n",
        "print(answer7)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7dc00908",
      "metadata": {
        "id": "7dc00908"
      },
      "source": [
        "### Q8: Hourly request distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "a77f3e12",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a77f3e12",
        "outputId": "1ce5c207-03c6-44ce-a324-42b82a5f0fde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer 8:\n",
            "{0.0: 11598, 1.0: 9913, 2.0: 9403, 3.0: 8147, 4.0: 7820, 5.0: 8283, 6.0: 9798, 7.0: 11930, 8.0: 17351, 9.0: 21681, 10.0: 25713, 11.0: 28665, 12.0: 26845, 13.0: 30089, 14.0: 29792, 15.0: 28149, 16.0: 28286, 17.0: 23312, 18.0: 17862, 19.0: 17325, 20.0: 17488, 21.0: 15965, 22.0: 14587, 23.0: 13613}\n"
          ]
        }
      ],
      "source": [
        "def hourly_request_distribution() -> dict[int, int]:\n",
        "    \"\"\"\n",
        "    Q8: Hourly request distribution.\n",
        "\n",
        "    Objective:\n",
        "        Count the number of requests made during each hour (00 to 23).\n",
        "        Useful for understanding traffic peaks.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary mapping hour (int) to request count.\n",
        "              Example: {0: 120, 1: 90, ..., 23: 80}\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: Implement logic for hourly distribution\n",
        "\n",
        "    df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')\n",
        "\n",
        "    df['hour'] = df['datetime'].dt.hour\n",
        "    return df['hour'].value_counts().sort_index().to_dict()\n",
        "\n",
        "\n",
        "answer8 = hourly_request_distribution()\n",
        "print(\"Answer 8:\")\n",
        "print(answer8)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "363b7083",
      "metadata": {
        "id": "363b7083"
      },
      "source": [
        "### Q9: Top 10 most requested filenames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "91168ad7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91168ad7",
        "outputId": "3a6f1702-bb2e-4fb6-c126-f6fd250c71e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer 9:\n",
            "[('index.html', 139528), ('3.gif', 24006), ('2.gif', 23595), ('4.gif', 8018), ('244.gif', 5148), ('5.html', 5010), ('4097.gif', 4874), ('8870.jpg', 4492), ('6733.gif', 4278), ('8472.gif', 3843)]\n"
          ]
        }
      ],
      "source": [
        "def top_10_most_requested_filenames() -> list[tuple[str, int]]:\n",
        "    \"\"\"\n",
        "    Q9: Top 10 most requested filenames.\n",
        "\n",
        "    Objective:\n",
        "        Identify the most commonly requested URLs (irrespective of status code).\n",
        "\n",
        "    Returns:\n",
        "        list: A list of tuples (filename, count), sorted by count in descending order.\n",
        "                Example: [('index.html', 500), ...]\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: Implement logic to find top 10 most requested filenames\n",
        "\n",
        "    top_files = df['file'].value_counts().head(10)\n",
        "    return list(top_files.items())\n",
        "\n",
        "\n",
        "answer9 = top_10_most_requested_filenames()\n",
        "print(\"Answer 9:\")\n",
        "print(answer9)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eedb4778",
      "metadata": {
        "id": "eedb4778"
      },
      "source": [
        "### Q10: HTTP response code distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "bd4453ed",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd4453ed",
        "outputId": "82587645-e058-49e0-a7d6-3633e3a04624"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer 10:\n",
            "{200: 568345, 302: 30295, 304: 97792, 400: 15, 401: 46, 403: 4741, 404: 23517, 500: 42, 501: 43}\n"
          ]
        }
      ],
      "source": [
        "def response_code_distribution() -> dict[int, int]:\n",
        "    \"\"\"\n",
        "    Q10: HTTP response code distribution.\n",
        "\n",
        "    Objective:\n",
        "        Count how often each HTTP status code appears in the logs.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary mapping HTTP status codes (as int) to their frequency.\n",
        "              Example: {200: 150000, 404: 3000}\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: Implement logic for response code counts\n",
        "\n",
        "    return df['status'].value_counts().sort_index().to_dict()\n",
        "\n",
        "\n",
        "answer10 = response_code_distribution()\n",
        "print(\"Answer 10:\")\n",
        "print(answer10)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "poetry-x2j_aZzr-py3.12",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}